{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge, ridge_regression, Lasso, LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, r_regression\n",
    "from sympy import Point\n",
    "import os, shutil\n",
    "from scipy.stats import percentileofscore\n",
    "import math\n",
    "from sqlalchemy import create_engine\n",
    "np.warnings = warnings\n",
    "\n",
    "%store -r transformed_defence_data\n",
    "%store -r evenStrengthD_names\n",
    "%store -r transformed_ppD_data\n",
    "%store -r powerPlayD_names\n",
    "%store -r transformed_pkD_data\n",
    "%store -r penaltyKillD_names\n",
    "%store -r transformed_forward_data\n",
    "%store -r evenStrengthF_names\n",
    "%store -r transformed_ppF_data\n",
    "%store -r powerPlayF_names\n",
    "%store -r transformed_pkF_data\n",
    "%store -r penaltyKillF_names\n",
    "\n",
    "%store -r evenStrengthF\n",
    "%store -r powerPlayF\n",
    "%store -r penaltyKillF\n",
    "%store -r evenStrengthD\n",
    "%store -r penaltyKillD\n",
    "%store -r powerPlayD\n",
    "\n",
    "%store -r evenStrengthG\n",
    "%store -r powerPlayG\n",
    "%store -r penaltyKillG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a transformer to scale the data before doing regression analysis\n",
    "def transformer(df):\n",
    "    pt = PowerTransformer()\n",
    "    pt.set_output(transform='pandas')\n",
    "    new_df = pt.fit_transform(df)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the percentile of each player's stats in a given dataframe\n",
    "def get_percentile_rank(df):\n",
    "    return df.rank(pct=True).mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the important \"above-average\" stats so that we can perform regression analysis\n",
    "def calculateAboveAverageStats(evenStrength, powerPlay, penaltyKill):\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # Filter each type of game situation so that each player plays at least x seconds to avoid outliers\n",
    "    evenStrength = evenStrength.loc[evenStrength.icetime > 5000]\n",
    "    powerPlay = powerPlay.loc[powerPlay.icetime > 3000]\n",
    "    penaltyKill = penaltyKill.loc[penaltyKill.icetime > 3000]\n",
    "\n",
    "    # Split Names and data for each game situation\n",
    "    EV_name, EV_data = evenStrength.iloc[:, :5], evenStrength.iloc[:,6:]\n",
    "    PP_name, PP_data = powerPlay.iloc[:, :5], powerPlay.iloc[:,6:]\n",
    "    PK_name, PK_data = penaltyKill.iloc[:, :5], penaltyKill.iloc[:,6:]\n",
    "\n",
    "    # Add prefix for even strength stats\n",
    "    EV_data = EV_data.add_prefix(\"EV_\")\n",
    "\n",
    "    # Add team_rank and cap_hit statistics\n",
    "    # team_rank = evenStrength[\"team_rank\"]\n",
    "    # team_rank.reset_index(drop=True, inplace=True)\n",
    "    # cap_hit = evenStrength[\"cap_hit\"]\n",
    "    # cap_hit.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Add prefixes for each game situation\n",
    "    PP_data = PP_data.add_prefix(\"PP_\")\n",
    "    PK_data = PK_data.add_prefix(\"PK_\")\n",
    "\n",
    "    # Divide each piece of information by seconds played, then subtract it from the average player in each stat\n",
    "    EV_data.iloc[:, 9:] = EV_data.iloc[:, 9:].div(EV_data.EV_icetime, axis=0)\n",
    "    PP_data.iloc[:, 9:] = PP_data.iloc[:, 9:].div(PP_data.PP_icetime, axis=0)\n",
    "    PK_data.iloc[:, 9:] = PK_data.iloc[:, 9:].div(PK_data.PK_icetime, axis=0)\n",
    "\n",
    "    EV_avg = EV_data.mean().drop('EV_icetime')\n",
    "    PP_avg = PP_data.mean().drop(\"PP_icetime\")\n",
    "    PK_avg = PK_data.mean().drop(\"PK_icetime\")\n",
    "\n",
    "\n",
    "    EV_data.iloc[:,1:] = (EV_data.iloc[:,1:] - EV_avg).mul(EV_data.EV_icetime, axis=0)\n",
    "    EV_data.iloc[:,1:9] = EV_data.iloc[:, 1:9].div(EV_data.EV_icetime, axis=0)\n",
    "    PP_data.iloc[:,1:] = (PP_data.iloc[:,1:] - PP_avg).mul(PP_data.PP_icetime, axis=0)\n",
    "    PP_data.iloc[:,1:9] = PP_data.iloc[:, 1:9].div(PP_data.PP_icetime, axis=0)\n",
    "    PK_data.iloc[:,1:] = (PK_data.iloc[:,1:] - PK_avg).mul(PK_data.PK_icetime, axis=0)\n",
    "    PK_data.iloc[:,1:9] = PK_data.iloc[:, 1:9].div(PK_data.PK_icetime, axis=0)\n",
    "\n",
    "    # Merge all data into a single dataframe\n",
    "    evenStrength = pd.concat([EV_name, EV_data], axis=1)\n",
    "    powerPlay = pd.concat([PP_name, PP_data], axis=1)\n",
    "    penaltyKill = pd.concat([PK_name, PK_data], axis=1)\n",
    "\n",
    "    full_df = pd.merge(evenStrength, powerPlay, how='left', on=['playerId', 'season', 'name', 'team', 'position'])\n",
    "    full_df = pd.merge(full_df, penaltyKill, how='left', on=['playerId', 'season', 'name', 'team', 'position'])\n",
    "    full_df.fillna(0, inplace=True)\n",
    "\n",
    "    new_df[['playerId', 'season', 'name', 'team', 'position', 'EV_icetime', 'PP_icetime', 'PK_icetime']] = full_df[['playerId', 'season', 'name', 'team', 'position', 'EV_icetime', 'PP_icetime', 'PK_icetime']]\n",
    "    # new_df[\"team_rank\"] = team_rank\n",
    "    # new_df[\"cap_hit\"] = cap_hit\n",
    "\n",
    "    # 1. Calculate IG\n",
    "    new_df[\"Individual_Goals\"] = full_df[\"EV_I_F_goals\"] + full_df[\"PP_I_F_goals\"] + full_df[\"PK_I_F_goals\"]\n",
    "\n",
    "    # 2. Calculate Individual primary assists\n",
    "    new_df[\"Individual_primaryAssists\"] = full_df[\"EV_I_F_primaryAssists\"] + full_df[\"PP_I_F_primaryAssists\"] + full_df[\"PK_I_F_primaryAssists\"]\n",
    "\n",
    "    # 3. Secondary Assists above Average\n",
    "    new_df[\"Individual_secondaryAssists\"] = full_df[\"EV_I_F_secondaryAssists\"] + full_df[\"PP_I_F_secondaryAssists\"] + full_df[\"PK_I_F_secondaryAssists\"]\n",
    "\n",
    "    # 4. Calculate total production\n",
    "    new_df[\"Production\"] = new_df[\"Individual_Goals\"] + new_df[\"Individual_primaryAssists\"] + new_df[\"Individual_secondaryAssists\"]\n",
    "\n",
    "    # 5. Calculate Penalty Differential\n",
    "    new_df[\"Penalty_Differential\"] = ((full_df[\"EV_penaltiesDrawn\"] + full_df[\"PP_penaltiesDrawn\"] + full_df[\"PK_penaltiesDrawn\"]) -\n",
    "                                      (full_df[\"EV_penalties\"] + full_df[\"PP_penalties\"] + full_df[\"PK_penalties\"])  )\n",
    "\n",
    "    # 6. Even Strength xGoals for %: onIce_xGoalsPercentage (EV) scaled by 100\n",
    "    new_df[\"EV_xGoalsPercentage\"] = full_df[\"EV_onIce_xGoalsPercentage\"]\n",
    "\n",
    "    # 7. Even strength chances given up: OnIce_A_xGoals (EV)\n",
    "    new_df[\"EV_xGoals_Against\"] = -1* (full_df[\"EV_OnIce_A_xGoals\"] + full_df[\"EV_OnIce_A_flurryAdjustedxGoals\"] + full_df[\"EV_OnIce_A_scoreVenueAdjustedxGoals\"]) / 3\n",
    "\n",
    "    # 8. Powerplay Chances: (I_F_xGoals (PP) + OnIce_F_xGoals (PP)) - give a boost if you are getting you own chances\n",
    "    new_df[\"PP_Chances\"] = full_df[\"PP_I_F_xGoals\"] + full_df[\"PP_OnIce_F_xGoals\"]\n",
    "\n",
    "    # 9. Even strength Chances : (I_F_xGoals (EV) + OnIce_F_xGoals (EV)) - give a boost if you are getting you own chances\n",
    "    new_df[\"EV_Chances\"] = full_df[\"EV_I_F_xGoals\"] + full_df[\"EV_OnIce_F_xGoals\"]\n",
    "\n",
    "    # 10. Penalty Kill Chances given up: Onice_A_xGoals (PK)\n",
    "    new_df[\"PK_xGoals_Against\"] = -1* (full_df[\"PK_OnIce_A_xGoals\"] + full_df[\"PK_OnIce_A_flurryAdjustedxGoals\"] + full_df[\"PK_OnIce_A_scoreVenueAdjustedxGoals\"]) / 3\n",
    "\n",
    "    # 11. Powerplay expected +/-: OnIce_F_goals (PP) - OnIce_A_goals (PP)\n",
    "    new_df[\"PP_differential\"] = full_df[\"PP_OnIce_F_goals\"] - full_df[\"PP_OnIce_A_goals\"]\n",
    "\n",
    "    # 12. Penalty Kill expected +/-: OnIce_F_goals (PK) - OnIce_A_goals (PK)\n",
    "    new_df[\"PK_differential\"] = full_df[\"PK_OnIce_F_goals\"] - full_df[\"PK_OnIce_A_goals\"]\n",
    "\n",
    "    # 13. EV +/-: OnIce_F_goals (EV) - OnIce_A_goals (EV)\n",
    "    new_df[\"EV_differential\"] = full_df[\"EV_OnIce_F_goals\"] - full_df[\"EV_OnIce_A_goals\"]\n",
    "\n",
    "    # 14. Finishing: finishing (goals - xGoals)\n",
    "    new_df[\"Finishing\"] = ((full_df[\"EV_I_F_goals\"] + full_df[\"PP_I_F_goals\"] + full_df[\"PK_I_F_goals\"]) - \n",
    "                           (full_df[\"EV_I_F_xGoals\"] + full_df[\"PP_I_F_xGoals\"] + full_df[\"PK_I_F_xGoals\"]))\n",
    "    # 15. Physicality: I_F_hits\n",
    "    new_df[\"Physicality\"] = full_df[\"EV_I_F_hits\"] + full_df[\"PP_I_F_hits\"] + full_df[\"PK_I_F_hits\"]\n",
    "\n",
    "    # 16. Calculate defensive actions (blocks + takeaways)\n",
    "    # new_df[\"Defensive_Actions\"] = (full_df[\"EV_shotsBlockedByPlayer\"] + full_df[\"PK_shotsBlockedByPlayer\"] + full_df[\"PP_shotsBlockedByPlayer\"]\n",
    "    #                                 + full_df[\"EV_I_F_takeaways\"] + full_df[\"PP_I_F_takeaways\"] + full_df[\"PK_I_F_takeaways\"])\n",
    "\n",
    "    # 16. Calculate Shots against\n",
    "    new_df[\"EV_Shots_Against\"] = -1 * (full_df[\"EV_OnIce_A_shotAttempts\"])\n",
    "\n",
    "    # 17. EV High Danger Chances Against\n",
    "    new_df[\"EV_HighDangerAgainst\"] = -1* (full_df[\"EV_OnIce_A_highDangerxGoals\"] + full_df[\"EV_OnIce_A_highDangerShots\"])\n",
    "\n",
    "    # 18. PK High Danger Chances Against\n",
    "    new_df[\"PK_HighDangerAgainst\"] = -1* (full_df[\"PK_OnIce_A_highDangerxGoals\"] + full_df[\"PK_OnIce_A_highDangerShots\"])\n",
    "\n",
    "    # 19. High Danger chances for\n",
    "    new_df[\"High_Danger_Chances_For\"] = (full_df[\"EV_I_F_highDangerxGoals\"] + full_df[\"PP_I_F_highDangerxGoals\"] + full_df[\"PK_I_F_highDangerxGoals\"]\n",
    "                                         + full_df[\"EV_I_F_highDangerShots\"] + full_df[\"PP_I_F_highDangerShots\"] + full_df[\"PK_I_F_highDangerShots\"])\n",
    "\n",
    "    # 20. Calculate GameScore\n",
    "    new_df[\"GameScore\"] = full_df[\"EV_gameScore\"] + full_df[\"PP_gameScore\"] + full_df[\"PK_gameScore\"]\n",
    "\n",
    "    # 21. Calculate even strength defensive imapact (implemented in future)\n",
    "    new_df[\"EV_Defensive_Impact\"] = (full_df[\"EV_OnIce_A_xGoals\"] - full_df[\"EV_OffIce_A_xGoals\"])\n",
    "\n",
    "    return new_df\n",
    "\n",
    "# Calculate the above average stats for forwards and defence\n",
    "modelF = calculateAboveAverageStats(evenStrengthF, powerPlayF, penaltyKillF)\n",
    "modelD = calculateAboveAverageStats(evenStrengthD, powerPlayD, penaltyKillD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'team_rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'team_rank'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Calculate the \"above-average\" stats for goalies\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m modelG \u001b[38;5;241m=\u001b[39m \u001b[43mcalculateAboveAverageGoalieStats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevenStrengthG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpowerPlayG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenaltyKillG\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 34\u001b[0m, in \u001b[0;36mcalculateAboveAverageGoalieStats\u001b[0;34m(evenStrength, powerPlay, penaltyKill)\u001b[0m\n\u001b[1;32m     31\u001b[0m EV_data \u001b[38;5;241m=\u001b[39m EV_data\u001b[38;5;241m.\u001b[39madd_prefix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEV_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Add team_rank and cap_hit stats\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m team_rank \u001b[38;5;241m=\u001b[39m \u001b[43mevenStrength\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteam_rank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m team_rank\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m cap_hit \u001b[38;5;241m=\u001b[39m evenStrength[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcap_hit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'team_rank'"
     ]
    }
   ],
   "source": [
    "# Calculate the important \"above-average\" stats for goaltenders\n",
    "def calculateAboveAverageGoalieStats(evenStrength, powerPlay, penaltyKill):\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # Filter each type of game situation so that each player plays at least x seconds to avoid outliers\n",
    "    evenStrength = evenStrength.loc[evenStrength.icetime > 5000].copy()\n",
    "    powerPlay = powerPlay.loc[powerPlay.icetime > 3000].copy()\n",
    "    penaltyKill = penaltyKill.loc[penaltyKill.icetime > 3000].copy()\n",
    "\n",
    "    # Calculate GSAE, Low_Danger, Medium_Danger, and High_Danger stats for all situations\n",
    "    evenStrength[\"GSAE\"] = evenStrength[\"xGoals\"] - evenStrength[\"goals\"]\n",
    "    \n",
    "    evenStrength[\"Low_Danger\"] = evenStrength[\"lowDangerxGoals\"] - evenStrength[\"lowDangerGoals\"]\n",
    "    evenStrength[\"Medium_Danger\"] = evenStrength[\"mediumDangerxGoals\"] - evenStrength[\"mediumDangerGoals\"]\n",
    "    evenStrength[\"High_Danger\"] = evenStrength[\"highDangerxGoals\"] - evenStrength[\"highDangerGoals\"]\n",
    "\n",
    "    powerPlay[\"GSAE\"] = powerPlay[\"xGoals\"] - powerPlay[\"goals\"]\n",
    "    powerPlay[\"Low_Danger\"] = powerPlay[\"lowDangerxGoals\"] - powerPlay[\"lowDangerGoals\"]\n",
    "    powerPlay[\"Medium_Danger\"] = powerPlay[\"mediumDangerxGoals\"] - powerPlay[\"mediumDangerGoals\"]\n",
    "    powerPlay[\"High_Danger\"] = powerPlay[\"highDangerxGoals\"] - powerPlay[\"highDangerGoals\"]\n",
    "\n",
    "    penaltyKill[\"GSAE\"] = penaltyKill[\"xGoals\"] - penaltyKill[\"goals\"]\n",
    "    penaltyKill[\"Low_Danger\"] = penaltyKill[\"lowDangerxGoals\"] - penaltyKill[\"lowDangerGoals\"]\n",
    "    penaltyKill[\"Medium_Danger\"] = penaltyKill[\"mediumDangerxGoals\"] - penaltyKill[\"mediumDangerGoals\"]\n",
    "    penaltyKill[\"High_Danger\"] = penaltyKill[\"highDangerxGoals\"] - penaltyKill[\"highDangerGoals\"]\n",
    "\n",
    "    # Split Names and data for each game situation\n",
    "    EV_name, EV_data = evenStrength.iloc[:, :5], evenStrength.iloc[:,6:]\n",
    "    PP_name, PP_data = powerPlay.iloc[:, :5], powerPlay.iloc[:,6:]\n",
    "    PK_name, PK_data = penaltyKill.iloc[:, :5], penaltyKill.iloc[:,6:]\n",
    "    EV_data = EV_data.add_prefix(\"EV_\")\n",
    "\n",
    "    # Add team_rank and cap_hit stats\n",
    "    # team_rank = evenStrength[\"team_rank\"]\n",
    "    # team_rank.reset_index(drop=True, inplace=True)\n",
    "    # cap_hit = evenStrength[\"cap_hit\"]\n",
    "    # cap_hit.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add prefixes to differentiate stats\n",
    "    PP_data = PP_data.add_prefix(\"PP_\")\n",
    "    PK_data = PK_data.add_prefix(\"PK_\")\n",
    "\n",
    "    # Divide every goalie's total stats by their seconds played\n",
    "    EV_data.iloc[:, 1:] = EV_data.iloc[:, 1:].div(EV_data.EV_icetime, axis=0)\n",
    "    PP_data.iloc[:, 1:] = PP_data.iloc[:, 1:].div(PP_data.PP_icetime, axis=0)\n",
    "    PK_data.iloc[:, 1:] = PK_data.iloc[:, 1:].div(PK_data.PK_icetime, axis=0)\n",
    "\n",
    "    # Calculate the average player\n",
    "    EV_avg = EV_data.mean().drop('EV_icetime')\n",
    "    PP_avg = PP_data.mean().drop(\"PP_icetime\")\n",
    "    PK_avg = PK_data.mean().drop(\"PK_icetime\")\n",
    "\n",
    "    # Calcualte the \"above-average\" versions of the statistics\n",
    "    EV_data.iloc[:,1:] = (EV_data.iloc[:,1:] - EV_avg).mul(EV_data.EV_icetime, axis=0)\n",
    "    PP_data.iloc[:,1:] = (PP_data.iloc[:,1:] - PP_avg).mul(PP_data.PP_icetime, axis=0)\n",
    "    PK_data.iloc[:,1:] = (PK_data.iloc[:,1:] - PK_avg).mul(PK_data.PK_icetime, axis=0)\n",
    "\n",
    "    # Merge the 3 situations into one dataframe\n",
    "    evenStrength = pd.concat([EV_name, EV_data], axis=1)\n",
    "    powerPlay = pd.concat([PP_name, PP_data], axis=1)\n",
    "    penaltyKill = pd.concat([PK_name, PK_data], axis=1)\n",
    "\n",
    "    full_df = pd.merge(evenStrength, powerPlay, how='left', on=['playerId', 'season', 'name', 'team', 'position'])\n",
    "    full_df = pd.merge(full_df, penaltyKill, how='left', on=['playerId', 'season', 'name', 'team', 'position'])\n",
    "    \n",
    "    full_df.fillna(0, inplace=True)\n",
    "\n",
    "    new_df[['playerId', 'season', 'name', 'team', 'position', 'EV_icetime', 'PP_icetime', 'PK_icetime']] = full_df[['playerId', 'season', 'name', 'team', 'position', 'EV_icetime', 'PP_icetime', 'PK_icetime']]\n",
    "    # new_df[\"team_rank\"] = team_rank\n",
    "    # new_df[\"cap_hit\"] = cap_hit\n",
    "\n",
    "    # Calculate the total above average versions of the stats\n",
    "    new_df[\"GSAE\"] = full_df[\"EV_GSAE\"] + full_df[\"PP_GSAE\"] + full_df[\"PK_GSAE\"]\n",
    "    new_df[\"Rebound_Control\"] = full_df[\"EV_rebounds\"] + full_df[\"PP_rebounds\"] + full_df[\"PK_rebounds\"]\n",
    "    new_df[\"Low_Danger\"] = full_df[\"EV_Low_Danger\"] + full_df[\"PP_Low_Danger\"] + full_df[\"PK_Low_Danger\"]\n",
    "    new_df[\"Medium_Danger\"] = full_df[\"EV_Medium_Danger\"] + full_df[\"PP_Medium_Danger\"] + full_df[\"PK_Medium_Danger\"]\n",
    "    new_df[\"High_Danger\"] = full_df[\"EV_High_Danger\"] + full_df[\"PP_High_Danger\"] + full_df[\"PK_High_Danger\"]\n",
    "\n",
    "    return new_df\n",
    "\n",
    "# Calculate the \"above-average\" stats for goalies\n",
    "modelG = calculateAboveAverageGoalieStats(evenStrengthG, powerPlayG, penaltyKillG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate team strength, which is the sum of each above average statistic\n",
    "def get_team_strength_above_avg(modelF, modelD, modelG=pd.DataFrame()):\n",
    "    full_df = pd.concat([modelF, modelD, modelG])\n",
    "    full_df.drop(columns=[\"playerId\", \"season\", \"name\", \"position\", \"EV_icetime\", \"PP_icetime\", \"PK_icetime\", \"team_rank\"], inplace=True)\n",
    "    return full_df.groupby([\"team\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, train_size=0.75, random_state=20)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.46875\n",
      "(32, 11)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# Calculate team strength\n",
    "team_strength = get_team_strength_above_avg(modelF, modelD, modelG)\n",
    "\n",
    "# Get the team points for the 2023-2024 regular season\n",
    "team_points = {\"team\": [\"NYR\", \"DAL\", \"CAR\", \"WPG\", \"FLA\", \"VAN\", \"BOS\", \"COL\", \"EDM\", \"TOR\", \"NSH\", \"LAK\", \"TBL\",\n",
    "                        \"VGK\", \"NYI\", \"STL\", \"WSH\", \"DET\", \"PIT\", \"MIN\", \"PHI\", \"BUF\", 'NJD', \"CGY\", \"SEA\", \"OTT\",\n",
    "                        \"ARI\", \"MTL\", \"CBJ\", \"ANA\", \"CHI\", \"SJS\"],\n",
    "                \"team_points_above_avg\": [114, 113, 111, 110, 110, 109, 109, 107, 104, 102, 99, 99, 98, 98, 94, 92, 91, 91, 88, 87, 87, 84, 81, 81, 81, 78, 77, 76, 66, 59, 52, 47]\n",
    "                }\n",
    "\n",
    "# Calculate the average points\n",
    "avg_points = sum(team_points[\"team_points_above_avg\"]) / len(team_points[\"team_points_above_avg\"])\n",
    "\n",
    "print(avg_points)\n",
    "\n",
    "team_points = pd.DataFrame.from_dict(team_points)\n",
    "team_strength = pd.merge(team_strength, team_points, on=[\"team\"])\n",
    "team_strength.to_csv('./pwaaRankings/teamStrength.csv', index=False)\n",
    "transformed_training_set = team_strength.copy()\n",
    "team_strength_train = transformed_training_set[[\"Individual_Goals\", \"Individual_primaryAssists\", \"EV_Chances\", \"PP_Chances\", \"Penalty_Differential\", \n",
    "                                                \"EV_xGoals_Against\", \"PK_xGoals_Against\", \n",
    "                                                \"EV_Shots_Against\", \"GSAE\",\n",
    "                                                \"Low_Danger\", \"High_Danger\", \"team_points_above_avg\"]]\n",
    "\n",
    "# Scale the data and set the team points as our target variable\n",
    "trans = transformer(team_strength_train)\n",
    "target = trans[\"team_points_above_avg\"].to_numpy()\n",
    "\n",
    "data = trans.drop(columns=[\"team_points_above_avg\"]).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_split_data(data, target)\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minimize ||y — Xw||² + alpha * ||w||²\n",
    "\n",
    "w = inv(X^TX + alpha * I) * X^Ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2171321 ,  0.23384958,  0.02997938,  0.07451154,  0.18528449,\n",
       "        0.17212594, -0.02251298,  0.06868605,  0.2535772 ,  0.17589477,\n",
       "       -0.01973187])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the ridge regression weights based on the minimization function above and the derived formula for the weights\n",
    "def get_ridge_regression_params(X, y, alpha):\n",
    "\n",
    "    xtx = X.T @ X\n",
    "    alpha_matrix = alpha * np.identity(xtx.shape[0])\n",
    "    xty = X.T @ y\n",
    "    inverse = np.linalg.inv(xtx + alpha_matrix)\n",
    "    return inverse @ xty\n",
    "\n",
    "get_ridge_regression_params(X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the mean squared error\n",
    "def get_mean_squared_error(y_truth, y_pred):\n",
    "    return np.mean((y_truth -y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00366676717951471\n",
      "[0.19399595 0.21151239 0.01097    0.11674568 0.12576079 0.19035573\n",
      " 0.04220381 0.08002503 0.16982338 0.28053761 0.09408487]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Individual_Goals',\n",
       " 'Individual_primaryAssists',\n",
       " 'EV_Chances',\n",
       " 'PP_Chances',\n",
       " 'Penalty_Differential',\n",
       " 'EV_xGoals_Against',\n",
       " 'PK_xGoals_Against',\n",
       " 'EV_Shots_Against',\n",
       " 'GSAE',\n",
       " 'Low_Danger',\n",
       " 'High_Danger',\n",
       " 'team_points_above_avg']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete an n-fold cross validation and return the most accurate weights\n",
    "def n_fold_cross_validation(X, y):\n",
    "\n",
    "    partitions = KFold(n_splits=15)\n",
    "\n",
    "    best_mse = 1000\n",
    "    best_w = 0\n",
    "\n",
    "    for fold, (train, test) in enumerate(partitions.split(X, y)):\n",
    "        #Split the data\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "        # Calculate the weights based on the trained data\n",
    "        w = get_ridge_regression_params(X_train, y_train, 5)\n",
    "\n",
    "        # Predict the points above average\n",
    "        y_pred = w.T @ X_test.T\n",
    "\n",
    "        # Calculate the mean squared error\n",
    "        mse = get_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        # Check to see which are the best weights\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_w = w\n",
    "        \n",
    "    print(best_mse)\n",
    "    print(best_w)\n",
    "\n",
    "    return best_w\n",
    "\n",
    "\n",
    "weights = n_fold_cross_validation(data, target)\n",
    "\n",
    "[\"Individual_Goals\", \"Individual_primaryAssists\", \"EV_Chances\", \"PP_Chances\", \"Penalty_Differential\", \n",
    "                                                \"EV_xGoals_Against\", \"PK_xGoals_Against\", \n",
    "                                                \"EV_Shots_Against\", \"GSAE\",\n",
    "                                                \"Low_Danger\", \"High_Danger\", \"team_points_above_avg\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the PWAA based on the weights\n",
    "transformed_training_set[\"PWAA\"] = trans.drop(columns=[\"team_points_above_avg\"]).dot(weights)\n",
    "transformed_training_set.to_csv('./pwaaRankings/teamStrength.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pwaa, offence, and defence stats for forwards and defencemen\n",
    "skater_coef, goalie_coef = weights[:8], weights[8:]\n",
    "offence_coef, defence_coef = skater_coef[:4], skater_coef[5:]\n",
    "skater_stats = [\"Individual_Goals\", \"Individual_primaryAssists\", \"EV_Chances\", \"PP_Chances\", \"Penalty_Differential\", \n",
    "                \"EV_xGoals_Against\", \"PK_xGoals_Against\", \"EV_Shots_Against\"]\n",
    "offence = [\"Individual_Goals\", \"Individual_primaryAssists\", \"EV_Chances\", \"PP_Chances\"]\n",
    "defence = [\"EV_xGoals_Against\", \"PK_xGoals_Against\", \"EV_Shots_Against\"]\n",
    "goalie_stats = [\"GSAE\", \"Low_Danger\", \"High_Danger\"]\n",
    "\n",
    "\n",
    "scaledModelF = transformer(modelF.iloc[:, 10:])\n",
    "scaledModelD = transformer(modelD.iloc[:, 10:])\n",
    "scaledModelG = transformer(modelG.iloc[:, 10:])\n",
    "\n",
    "modelF[\"Offence\"] = scaledModelF[offence].dot(offence_coef)\n",
    "modelF[\"Offence_Ranking\"] = get_percentile_rank(modelF[\"Offence\"])\n",
    "modelF[\"Defence\"] = scaledModelF[defence].dot(defence_coef)\n",
    "modelF[\"Defence_Ranking\"] = get_percentile_rank(modelF[\"Defence\"])\n",
    "modelF[\"Penalty_Ranking\"] = get_percentile_rank(modelF[\"Penalty_Differential\"])\n",
    "modelF[\"Physicality_Ranking\"] = get_percentile_rank(modelF[\"Physicality\"])\n",
    "modelF[\"Production_Ranking\"] = get_percentile_rank(modelF[\"Production\"])\n",
    "modelF[\"Finishing_Ranking\"] = get_percentile_rank(modelF[\"Finishing\"])\n",
    "modelF[\"PWAA\"] = scaledModelF[skater_stats].dot(skater_coef)\n",
    "modelF[\"PWAA_Ranking\"] = get_percentile_rank(modelF[\"PWAA\"])\n",
    "\n",
    "modelD[\"Offence\"] = scaledModelD[offence].dot(offence_coef)\n",
    "modelD[\"Offence_Ranking\"] = get_percentile_rank(modelD[\"Offence\"])\n",
    "modelD[\"Defence\"] = scaledModelD[defence].dot(defence_coef)\n",
    "modelD[\"Defence_Ranking\"] = get_percentile_rank(modelD[\"Defence\"])\n",
    "modelD[\"Penalty_Ranking\"] = get_percentile_rank(modelD[\"Penalty_Differential\"])\n",
    "modelD[\"Physicality_Ranking\"] = get_percentile_rank(modelD[\"Physicality\"])\n",
    "modelD[\"Production_Ranking\"] = get_percentile_rank(modelD[\"Production\"])\n",
    "modelD[\"Finishing_Ranking\"] = get_percentile_rank(modelD[\"Finishing\"])\n",
    "modelD[\"PWAA\"] = scaledModelD[skater_stats].dot(skater_coef)\n",
    "modelD[\"PWAA_Ranking\"] = get_percentile_rank(modelD[\"PWAA\"])\n",
    "\n",
    "modelG[\"PWAA\"] = scaledModelG[goalie_stats].dot(goalie_coef)\n",
    "modelG[[\"GSAE_Ranking\", \"Low_Danger_Ranking\", \"Medium_Danger_Ranking\", \"High_Danger_Ranking\", \"Rebound_Control_Ranking\"]] = get_percentile_rank(modelG[[\"GSAE\", \"Low_Danger\", \"Medium_Danger\", \"High_Danger\", \"Rebound_Control\"]])\n",
    "modelG[\"PWAA_Ranking\"] = get_percentile_rank(modelG[\"PWAA\"])\n",
    "\n",
    "modelF.to_csv(\"./pwaaRankings/aboveAvgF.csv\", index=False)\n",
    "modelD.to_csv(\"./pwaaRankings/aboveAvgD.csv\", index=False)\n",
    "modelG.to_csv(\"./pwaaRankings/aboveAvgG.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add data to posgres database\n",
    "engine = create_engine(\"postgresql://postgres:luszalytics@127.0.0.1:5432/hockey_data\")\n",
    "modelF.to_sql(\"PWAA_forwards\", engine, if_exists=\"replace\", index=False, schema=\"PWAA\")\n",
    "modelD.to_sql(\"PWAA_defence\", engine, if_exists='replace', index=False, schema=\"PWAA\")\n",
    "modelG.to_sql(\"PWAA_goalies\", engine, if_exists='replace', index=False, schema=\"PWAA\")\n",
    "transformed_training_set.to_sql(\"PWAA_teams\", engine, if_exists='replace', index=False, schema=\"PWAA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
